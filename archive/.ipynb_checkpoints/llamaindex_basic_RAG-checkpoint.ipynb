{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fb0b9e-f9cd-404f-bd8d-0273e94ac1fe",
   "metadata": {},
   "source": [
    "# RAG Example Using NVIDIA API Catalog and LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969cdab-82fc-4ce5-bde1-b4f629691f27",
   "metadata": {},
   "source": [
    "This notebook introduces how to use LlamaIndex to interact with NVIDIA hosted NIM microservices like chat, embedding, and reranking models to build a simple retrieval-augmented generation (RAG) application.\n",
    "\n",
    "Alternatively, for a more interactive experience with a graphical user interface, you can refer to our [code](https://github.com/jayrodge/llm-assistant-cloud-app/) and [YouTube video](https://www.youtube.com/watch?v=09uDCmLzYHA) for Gradio-based RAG Q&A reference application that also uses NVIDIA hosted NIM microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4253bd0-4313-4056-95f5-899a180879c2",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a084a00-b65d-483a-a7c6-b4c12e4272dd",
   "metadata": {},
   "source": [
    "#### RAG\n",
    "\n",
    "- RAG is a technique for augmenting LLM knowledge with additional data.\n",
    "- LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on.\n",
    "- If you want to build AI applications that can reason about private data or data introduced after a model's cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "- The process of bringing the appropriate information and inserting it into the model prompt is known as retrieval augmented generation (RAG).\n",
    "\n",
    "The preceding summary of RAG originates in the LangChain v0.2 tutorial [Build a RAG App](https://python.langchain.com/v0.2/docs/tutorials/rag/) tutorial in the LangChain v0.2 documentation.\n",
    "\n",
    "For comprehensive information, refer to the LLamaIndex documentation for [Building an LLM Application](https://docs.llamaindex.ai/en/stable/understanding/#:~:text=on%20your%20machine.-,Building%20a%20RAG%20pipeline,-%3A%20Retrieval%2DAugmented%20Generation).\n",
    "\n",
    "#### NIM\n",
    "\n",
    "- [NIM microservices](https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/) are containerized microservices that simplify the deployment of generative AI models like LLMs and are optimized to run on NVIDIA GPUs. \n",
    "- NIM microservices support models across domains like chat, embedding, reranking, and more from both the community and NVIDIA.\n",
    "\n",
    "#### NVIDIA API Catalog\n",
    "\n",
    "- [NVIDIA API Catalog](https://build.nvidia.com/explore/discover) is a hosted platform for accessing a wide range of microservices online.\n",
    "- You can test models on the catalog and then export them with an NVIDIA AI Enterprise license for on-premises or cloud deployment\n",
    "\n",
    "#### LlamaIndex Concepts\n",
    "\n",
    " - `Data connectors` ingest your existing data from their native source and format.\n",
    " - `Data indexes` structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
    " - `Engines` provide natural language access to your data for building context-augmented LLM apps.\n",
    "\n",
    "LlamaIndex also provides integrations like `llms-nvidia`, `embeddings-nvidia` & `nvidia-rerank` to work with NVIDIA microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300278-5ff4-47c4-ab70-c6584ef73c9f",
   "metadata": {},
   "source": [
    "## Installation and Requirements\n",
    "\n",
    "Create a Python environment (preferably with Conda) using Python version 3.10.14. \n",
    "To install Jupyter Lab, refer to the [installation](https://jupyter.org/install) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a52a0-7e5e-4064-9665-cb947d600f84",
   "metadata": {},
   "source": [
    "## Getting Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36287c2e-8708-4006-8adf-851f06cce02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv_llamaindex2/lib/python3.10/site-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.2\n",
      "    Uninstalling pip-22.0.2:\n",
      "      Successfully uninstalled pip-22.0.2\n",
      "Successfully installed pip-24.2\n",
      "Collecting llama-index-core==0.10.50\n",
      "  Using cached llama_index_core-0.10.50-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.27.2)\n",
      "Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.50)\n",
      "  Using cached llama_cloud-0.0.6-py3-none-any.whl.metadata (750 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (2.9.2)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.50) (0.14.0)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (2024.9.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.50) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.50) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.50) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.50) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.50) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.50) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.50) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.50) (24.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.50) (1.16.0)\n",
      "Using cached llama_index_core-0.10.50-py3-none-any.whl (15.4 MB)\n",
      "Using cached llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
      "Installing collected packages: llama-cloud, llama-index-core\n",
      "  Attempting uninstall: llama-cloud\n",
      "    Found existing installation: llama-cloud 0.1.0\n",
      "    Uninstalling llama-cloud-0.1.0:\n",
      "      Successfully uninstalled llama-cloud-0.1.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.14\n",
      "    Uninstalling llama-index-core-0.11.14:\n",
      "      Successfully uninstalled llama-index-core-0.11.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-cloud>=0.0.11, but you have llama-cloud 0.0.6 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-llms-openai 0.2.9 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-llms-openai-like 0.1.3 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.2.9 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-parse 0.5.6 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-cloud-0.0.6 llama-index-core-0.10.50\n",
      "Collecting llama-index-readers-file==0.1.25\n",
      "  Using cached llama_index_readers_file-0.1.25-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (4.12.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (0.10.50)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.1.25) (2.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.27.2)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.9.2)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.14.0)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.9.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.16.0)\n",
      "Using cached llama_index_readers_file-0.1.25-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: llama-index-readers-file\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.2.2\n",
      "    Uninstalling llama-index-readers-file-0.2.2:\n",
      "      Successfully uninstalled llama-index-readers-file-0.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-readers-file<0.3.0,>=0.2.0, but you have llama-index-readers-file 0.1.25 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-readers-file-0.1.25\n",
      "Collecting llama-index-llms-nvidia==0.1.3\n",
      "  Using cached llama_index_llms_nvidia-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-nvidia==0.1.3) (0.10.50)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.17 (from llama-index-llms-nvidia==0.1.3)\n",
      "  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.2.0,>=0.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-nvidia==0.1.3) (0.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.27.2)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-core<0.11.0,>=0.10.0 (from llama-index-llms-nvidia==0.1.3)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.9.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (4.44.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.0.3)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.9.11)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.1.1)\n",
      "Requirement already satisfied: filelock in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (24.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.2.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.16.0)\n",
      "Using cached llama_index_llms_nvidia-0.1.3-py3-none-any.whl (4.3 kB)\n",
      "Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core, llama-index-llms-openai, llama-index-llms-nvidia\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.50\n",
      "    Uninstalling llama-index-core-0.10.50:\n",
      "      Successfully uninstalled llama-index-core-0.10.50\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.9\n",
      "    Uninstalling llama-index-llms-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-llms-openai<0.3.0,>=0.2.9, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-readers-file<0.3.0,>=0.2.0, but you have llama-index-readers-file 0.1.25 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-llms-openai<0.3.0,>=0.2.9, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-cloud>=0.0.11, but you have llama-cloud 0.0.6 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-parse 0.5.6 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.10.68.post1 llama-index-llms-nvidia-0.1.3 llama-index-llms-openai-0.1.31\n",
      "Collecting llama-index-embeddings-nvidia==0.1.4\n",
      "  Using cached llama_index_embeddings_nvidia-0.1.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.9 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-embeddings-nvidia==0.1.4) (0.10.68.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.2.2)\n",
      "Using cached llama_index_embeddings_nvidia-0.1.4-py3-none-any.whl (5.5 kB)\n",
      "Installing collected packages: llama-index-embeddings-nvidia\n",
      "Successfully installed llama-index-embeddings-nvidia-0.1.4\n",
      "Collecting llama-index-postprocessor-nvidia-rerank==0.1.2\n",
      "  Using cached llama_index_postprocessor_nvidia_rerank-0.1.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.35 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-postprocessor-nvidia-rerank==0.1.2) (0.10.68.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.2.2)\n",
      "Using cached llama_index_postprocessor_nvidia_rerank-0.1.2-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: llama-index-postprocessor-nvidia-rerank\n",
      "Successfully installed llama-index-postprocessor-nvidia-rerank-0.1.2\n",
      "Requirement already satisfied: ipywidgets==8.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (3.0.13)\n",
      "Requirement already satisfied: decorator in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.3) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.3) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv_llamaindex2/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.1.3) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "!pip install --upgrade pip\n",
    "!pip install llama-index-core==0.10.50\n",
    "!pip install llama-index-readers-file==0.1.25\n",
    "!pip install llama-index-llms-nvidia==0.1.3\n",
    "!pip install llama-index-embeddings-nvidia==0.1.4\n",
    "!pip install llama-index-postprocessor-nvidia-rerank==0.1.2\n",
    "!pip install ipywidgets==8.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04495732-c2db-4c97-91d0-96708814334d",
   "metadata": {},
   "source": [
    "To get started you need a `NVIDIA_API_KEY` to use NVIDIA AI Foundation models:\n",
    "\n",
    "1) Create a free account with [NVIDIA](https://build.nvidia.com/explore/discover).\n",
    "2) Click on your model of choice.\n",
    "3) Under Input select the Python tab, and click **Get API Key** and then click **Generate Key**.\n",
    "4) Copy and save the generated key as NVIDIA_API_KEY. From there, you should have access to the endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb51115-79f8-48c3-b3ee-d434916945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvidia_api_key.startswith(\"nvapi-\"), f\"{nvidia_api_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25656ab5-0046-4e27-be65-b3d3d547b4c6",
   "metadata": {},
   "source": [
    "## RAG Example using LLM and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e86bc0-e9c5-4a2b-be0e-7fca0331e886",
   "metadata": {},
   "source": [
    "### 1) Initialize the LLM\n",
    "\n",
    "`llama-index-llms-nvidia`, also known as NVIDIA's LLM connector,\n",
    "allows your connect to and generate from compatible models available on the NVIDIA API catalog.\n",
    "\n",
    "Here we will use **mixtral-8x7b-instruct-v0.1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f7bdd3-2c6f-4ba2-bd89-175cedbf4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings enables global configuration as a singleton object throughout your application.\n",
    "# Here, it is used to set the LLM, embedding model, and text splitter configurations globally.\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "# Here we are using mixtral-8x7b-instruct-v0.1 model from API Catalog\n",
    "Settings.llm = NVIDIA(model=\"meta/llama-3.1-405b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc87a6-2f83-4652-95f1-cf349db8bad6",
   "metadata": {},
   "source": [
    "### 2) Intiatlize the embedding\n",
    "\n",
    "We selected **NV-Embed-QA** as the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88f7838-b9f9-4fc5-8779-84df6cb26017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
    "Settings.embed_model = NVIDIAEmbedding(model=\"NV-Embed-QA\", truncate=\"END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9862f2e-5055-4fe4-818d-708091243d74",
   "metadata": {},
   "source": [
    "### 3) Obtain some toy text dataset\n",
    "Here we are loading a toy data from a text documents and in real-time data can be loaded from various sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b16b3-43ac-4269-9f37-05a33efe24fb",
   "metadata": {},
   "source": [
    "Real world documents can be very long, this makes it hard to fit in the context window of many models. Even for those models that could fit the full post in their context window, models can struggle to find information in very long inputs.\n",
    "\n",
    "To handle this we’ll split the Document into chunks for embedding and vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804c85f6-181b-4291-a685-d6b378015544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example we load a toy data set (it's a simple text file with some information about Sweden)\n",
    "TOY_DATA_PATH = \"/home/polabs2/Code/RPG_teacher/data/out\"\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=400)\n",
    "documents = SimpleDirectoryReader(TOY_DATA_PATH).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a7da3-b6e7-46f1-9c31-3c6ef5f04d56",
   "metadata": {},
   "source": [
    "Note:\n",
    " - `SimpleDirectoryReader` takes care of storing basic file information such as the filename, filepath, and file type as metadata by default. This metadata can be used to keep track of the source file, allowing us to use it later for citation or metadata filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867df18-11c8-45ea-b81c-1603459431f9",
   "metadata": {},
   "source": [
    "### 4) Process the documents into VectorStoreIndex\n",
    "\n",
    "In RAG, your data is loaded and prepared for queries or \"indexed\". User queries act on the index, which filters your data down to the most relevant context. This context and your query then go to the LLM along with a prompt, and the LLM provides a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7b2fbd-8cb1-4d68-9659-2426b9ecffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "# When you use from_documents, your Documents are split into chunks and parsed into Node objects\n",
    "# By default, VectorStoreIndex stores everything in memory\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe85dad-12bb-47d2-a407-9b89b5270d4e",
   "metadata": {},
   "source": [
    "### 5) Create a Query Engine to ask question over your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de3e07d-5fbe-4fe7-8f23-ed0b082f2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a Query engine for this index.\n",
    "query_engine = index.as_query_engine(similarity_top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4aa38b-ae1a-4d31-857b-55400b6233b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"What have I got in my pocket?\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What was the riddle Bilbo Baggins used to win the Ring from Gollum?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aa362c9-48ab-4646-bc29-bc2aca92505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilbo Baggins is a remarkable hobbit with a unique blend of resourcefulness, bravery, and cleverness. Although he comes from a respectable and comfortable family, he has a hint of adventure in his makeup, inherited from his mother's side, the Tooks. This latent sense of adventure remains dormant until he is about fifty years old, when he embarks on a journey that showcases his ability to think on his feet and rescue his companions from precarious situations. His small stature belies his significant impact, as seen in his daring rescue of his companions from spiders and his clandestine communication with Thorin, the chief of the dwarves, while in prison.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is Bilbo Baggins?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29478b0-0fb1-4678-93cd-b159dc9884a7",
   "metadata": {},
   "source": [
    "## RAG Example with LLM, Embedding & Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e763860-d4ca-491c-a11b-5bcf05a2ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"Create three open-ended questions on web site design that are also thematically set in the Hobbit.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a91ed-5905-474e-8d8e-f5d887638a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test a more complex query using the above LLM Embedding query_engine and see if the reranker can help.\n",
    "response = query_engine.query(    \"What are all the chapters in the Hobbit?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b048f0-6258-43af-a799-6e58859cba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "doc_data = pd.read_csv('/home/polabs2/Code/RPG_teacher/data/chapter_summary_notes.csv', delimiter='\\t', header=0)\n",
    "\n",
    "# Filter the data for the document \"hobbit\"\n",
    "doc_data = doc_data[doc_data['document'] == 'hobbit']\n",
    "print(doc_data.head(2))\n",
    "\n",
    "# Iterate over the rows in the DataFrame\n",
    "for i, row in doc_data.iterrows():\n",
    "    chapter = row['chapter']\n",
    "    text = row['text']\n",
    "    \n",
    "    # Generate the query string\n",
    "    q = f\"You are a helpful book summarizing assistant. Please use the provided context to summarize the following chapter into about 10 events: chapter {chapter} {text}\"\n",
    "    \n",
    "    # Send the query to the engine\n",
    "    response = query_engine.query(q)\n",
    "    \n",
    "    # Print the response\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3854c7-68a3-45b4-9e69-2c4e583d651f",
   "metadata": {},
   "source": [
    "### Enhancing accuracy for single data sources\n",
    "\n",
    "This example demonstrates how a re-ranking model can be used to combine retrieval results and improve accuracy during retrieval of documents.\n",
    "\n",
    "Typically, reranking is a critical piece of high-accuracy, efficient retrieval pipelines. Generally, there are two important use cases:\n",
    "\n",
    "- Combining results from multiple data sources\n",
    "- Enhancing accuracy for single data sources\n",
    "\n",
    "Here, we focus on demonstrating only the second use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8677e-a37f-42e2-8fea-4c4413f7d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will narrow the collection to 40 results and further narrow it to 4 with the reranker.\n",
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "\n",
    "reranker_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=40, node_postprocessors=[NVIDIARerank(top_n=4)]\n",
    ")\n",
    "\n",
    "response = reranker_query_engine.query(\n",
    "    \"What are the names of all the dwarves on Bilbo's adventure?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c289d-b10f-4bad-bb55-edc779e544f4",
   "metadata": {},
   "source": [
    "#### Note:\n",
    " - In this notebook, we used NVIDIA NIM microservices from the NVIDIA API Catalog.\n",
    " - The above APIs, NVIDIA (llms), NVIDIAEmbedding, and NVIDIARerank, also support self-hosted microservices.\n",
    " - Change the `base_url` to your deployed NIM URL\n",
    " - Example: NVIDIA(model=\"meta/llama3-8b-instruct\", base_url=\"http://your-nim-host-address:8000/v1\")\n",
    " - NIM can be hosted locally using Docker, following the [NVIDIA NIM for LLMs](https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea831a-76a5-431f-9b7f-f5bad5cb567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code snippet if you want to use a self-hosted NIM\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "llm = NVIDIA(model=\"meta/llama3-8b-instruct\", base_url=\"http://your-nim-host-address:8000/v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_llamaindex2)",
   "language": "python",
   "name": "venv_llamaindex2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
