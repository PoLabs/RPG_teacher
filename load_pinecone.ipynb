{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b57a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 documents loaded and indexed in novel.\n",
      "Textbook and novel documents have been indexed in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.legacy.vector_stores.pinecone import PineconeVectorStore\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize Pinecone\n",
    "api_key = \"d82b0e3a-acd5-4197-a10c-84245c2f9331\"  # Replace with your actual Pinecone API key\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "openai_api_key = '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'\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "index_name_textbook = 'european-history-index'\n",
    "index_name_novel = 'sherlock-holmes-index'\n",
    "\n",
    "# Create the Pinecone indexes for textbooks and novels\n",
    "if index_name_textbook not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name_textbook,\n",
    "        dimension=1536,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "if index_name_novel not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name_novel,\n",
    "        dimension=1536,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "    \n",
    "textbook_index = pc.Index(name=index_name_textbook)\n",
    "novel_index = pc.Index(name=index_name_novel)\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embeddings using OpenAI API.\"\"\"\n",
    "    response = client.embeddings.create(model=\"text-embedding-ada-002\", input=text)\n",
    "    embedding = response.data[0].embedding  # Use dot notation to access the embedding\n",
    "    return embedding\n",
    "\n",
    "def load_and_index_documents(index, doc_type, directory_path):\n",
    "    \"\"\"Load documents, generate embeddings, and index them into Pinecone.\"\"\"\n",
    "    reader = SimpleDirectoryReader(directory_path)\n",
    "    documents = reader.load_data()\n",
    "\n",
    "    vectors = []\n",
    "    for i, document in enumerate(documents):\n",
    "        content = document.get_content()\n",
    "        embedding = get_embedding(content)\n",
    "        vector = {\n",
    "            'id': f\"{doc_type}_{i}\",\n",
    "            'values': embedding,\n",
    "            'metadata': {'text': content}\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "\n",
    "    # Batch upsert for efficiency\n",
    "    batch_size = 100  # Adjust the batch size as needed\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i + batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "\n",
    "    print(f\"{len(documents)} documents loaded and indexed in {doc_type}.\")\n",
    "\n",
    "\n",
    "# Load and index textbook documents\n",
    "#load_and_index_documents(textbook_index, 'textbook', 'data/textbooks/European History')\n",
    "\n",
    "# Load and index novel documents\n",
    "load_and_index_documents(novel_index, 'novel', 'data/novels/Sherlock Holmes')\n",
    "\n",
    "print(\"Textbook and novel documents have been indexed in Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76e21dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'core', 'llms', 'readers']\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "print(dir(llama_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f848d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package llama_index:\n",
      "\n",
      "NAME\n",
      "    llama_index\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _bundle (package)\n",
      "    cli (package)\n",
      "    core (package)\n",
      "    legacy (package)\n",
      "\n",
      "SUBMODULES\n",
      "    llms\n",
      "    readers\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "help(llama_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0956d8ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.file.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.file.base'"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.file.base import SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63ea77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'file']\n"
     ]
    }
   ],
   "source": [
    "import llama_index.readers\n",
    "print(dir(llama_index.readers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005792d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSVReader', 'DocxReader', 'EpubReader', 'FlatReader', 'HTMLTagReader', 'HWPReader', 'IPYNBReader', 'ImageCaptionReader', 'ImageReader', 'ImageTabularChartReader', 'ImageVisionLLMReader', 'MarkdownReader', 'MboxReader', 'PDFReader', 'PagedCSVReader', 'PandasCSVReader', 'PandasExcelReader', 'PptxReader', 'PyMuPDFReader', 'RTFReader', 'UnstructuredReader', 'VideoAudioReader', 'XMLReader', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'docs', 'epub', 'flat', 'html', 'image', 'image_caption', 'image_deplot', 'image_vision_llm', 'ipynb', 'markdown', 'mbox', 'paged_csv', 'pymu_pdf', 'rtf', 'slides', 'tabular', 'unstructured', 'video_audio', 'xml']\n"
     ]
    }
   ],
   "source": [
    "import llama_index.readers.file\n",
    "print(dir(llama_index.readers.file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1928ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.llms.nvidia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnvidia\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NVIDIA\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.llms.nvidia'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.nvidia import NVIDIA \n",
    "from llama_index.llms.nvidia import NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5c510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_llamaindex2)",
   "language": "python",
   "name": "venv_llamaindex2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
