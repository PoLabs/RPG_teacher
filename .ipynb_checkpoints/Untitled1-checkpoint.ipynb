{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1488c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.file.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader  \u001b[38;5;66;03m# Correct import path for SimpleDirectoryReader\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     ServiceContext,\n\u001b[1;32m      7\u001b[0m     StorageContext,\n\u001b[1;32m      8\u001b[0m     load_index_from_storage,\n\u001b[1;32m      9\u001b[0m     GPTVectorStoreIndex,  \u001b[38;5;66;03m# Updated class for vector store\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnvidia\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NVIDIA  \u001b[38;5;66;03m# NVIDIA NeMo for language generation\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.file.base'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from llama_index.readers.file.base import SimpleDirectoryReader  # Correct import path for SimpleDirectoryReader\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    GPTVectorStoreIndex,  # Updated class for vector store\n",
    ")\n",
    "from llama_index.llms.nvidia import NVIDIA  # NVIDIA NeMo for language generation\n",
    "from llama_index.embeddings.nvidia import NVIDIAEmbedding  # NVIDIA Embedding model\n",
    "\n",
    "# Enable logging to see what's happening under the hood\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = \"data\"  # Directory to store data (e.g., text files)\n",
    "PERSIST_DIR = \"./storage\"  # Directory to store the persisted index\n",
    "\n",
    "# Set up NVIDIA API Key (required for hosted NIM)\n",
    "nvidia_api_key = os.environ.get(\"NVIDIA_API_KEY\")\n",
    "if not nvidia_api_key:\n",
    "    raise ValueError(\"Please set your NVIDIA_API_KEY as an environment variable.\")\n",
    "\n",
    "# Initialize NVIDIA NeMo models for LLM and embedding\n",
    "llm = NVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
    "embed_model = NVIDIAEmbedding(model=\"NV-Embed-QA\", truncate=\"END\")\n",
    "\n",
    "# Function to create or load the index\n",
    "def create_or_load_index():\n",
    "    if not os.path.exists(PERSIST_DIR):\n",
    "        # If no index exists, create one from the documents in the 'data' folder\n",
    "        print(\"No index found. Creating a new one...\")\n",
    "        documents = PDFReader().load_data(\"path/to/your/pdf/files\")\n",
    "        service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "        index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "        # Store the index for future use\n",
    "        index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "    else:\n",
    "        # Load the existing index from storage\n",
    "        print(\"Index found. Loading the existing index...\")\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "        index = load_index_from_storage(storage_context)\n",
    "    return index\n",
    "\n",
    "# Function to query the index\n",
    "def query_index(query_str):\n",
    "    index = create_or_load_index()\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(query_str)\n",
    "    print(\"Response:\", response)\n",
    "\n",
    "# Make sure the data folder exists and contains the required file\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "# Download the example document (Paul Graham essay) if it doesn't exist\n",
    "essay_path = os.path.join(DATA_DIR, \"paul_graham_essay.txt\")\n",
    "if not os.path.exists(essay_path):\n",
    "    essay_url = \"https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/paul_graham_essay.txt\"\n",
    "    print(f\"Downloading the Paul Graham essay to {essay_path}...\")\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(essay_url, essay_path)\n",
    "\n",
    "# Example usage: Query the index\n",
    "query_str = \"What did the author do growing up?\"\n",
    "query_index(query_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b2b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'core', 'llms', 'readers']\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "print(dir(llama_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7401ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package llama_index:\n",
      "\n",
      "NAME\n",
      "    llama_index\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _bundle (package)\n",
      "    cli (package)\n",
      "    core (package)\n",
      "    legacy (package)\n",
      "\n",
      "SUBMODULES\n",
      "    llms\n",
      "    readers\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "help(llama_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e1d9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.file.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.file.base'"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.file.base import SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e643f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'file']\n"
     ]
    }
   ],
   "source": [
    "import llama_index.readers\n",
    "print(dir(llama_index.readers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccc3ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSVReader', 'DocxReader', 'EpubReader', 'FlatReader', 'HTMLTagReader', 'HWPReader', 'IPYNBReader', 'ImageCaptionReader', 'ImageReader', 'ImageTabularChartReader', 'ImageVisionLLMReader', 'MarkdownReader', 'MboxReader', 'PDFReader', 'PagedCSVReader', 'PandasCSVReader', 'PandasExcelReader', 'PptxReader', 'PyMuPDFReader', 'RTFReader', 'UnstructuredReader', 'VideoAudioReader', 'XMLReader', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'docs', 'epub', 'flat', 'html', 'image', 'image_caption', 'image_deplot', 'image_vision_llm', 'ipynb', 'markdown', 'mbox', 'paged_csv', 'pymu_pdf', 'rtf', 'slides', 'tabular', 'unstructured', 'video_audio', 'xml']\n"
     ]
    }
   ],
   "source": [
    "import llama_index.readers.file\n",
    "print(dir(llama_index.readers.file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf079008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_llamaindex2)",
   "language": "python",
   "name": "venv_llamaindex2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
