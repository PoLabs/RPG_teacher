{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fb0b9e-f9cd-404f-bd8d-0273e94ac1fe",
   "metadata": {},
   "source": [
    "# RAG Example Using NVIDIA API Catalog and LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969cdab-82fc-4ce5-bde1-b4f629691f27",
   "metadata": {},
   "source": [
    "This notebook introduces how to use LlamaIndex to interact with NVIDIA hosted NIM microservices like chat, embedding, and reranking models to build a simple retrieval-augmented generation (RAG) application.\n",
    "\n",
    "Alternatively, for a more interactive experience with a graphical user interface, you can refer to our [code](https://github.com/jayrodge/llm-assistant-cloud-app/) and [YouTube video](https://www.youtube.com/watch?v=09uDCmLzYHA) for Gradio-based RAG Q&A reference application that also uses NVIDIA hosted NIM microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4253bd0-4313-4056-95f5-899a180879c2",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a084a00-b65d-483a-a7c6-b4c12e4272dd",
   "metadata": {},
   "source": [
    "#### RAG\n",
    "\n",
    "- RAG is a technique for augmenting LLM knowledge with additional data.\n",
    "- LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on.\n",
    "- If you want to build AI applications that can reason about private data or data introduced after a model's cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "- The process of bringing the appropriate information and inserting it into the model prompt is known as retrieval augmented generation (RAG).\n",
    "\n",
    "The preceding summary of RAG originates in the LangChain v0.2 tutorial [Build a RAG App](https://python.langchain.com/v0.2/docs/tutorials/rag/) tutorial in the LangChain v0.2 documentation.\n",
    "\n",
    "For comprehensive information, refer to the LLamaIndex documentation for [Building an LLM Application](https://docs.llamaindex.ai/en/stable/understanding/#:~:text=on%20your%20machine.-,Building%20a%20RAG%20pipeline,-%3A%20Retrieval%2DAugmented%20Generation).\n",
    "\n",
    "#### NIM\n",
    "\n",
    "- [NIM microservices](https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/) are containerized microservices that simplify the deployment of generative AI models like LLMs and are optimized to run on NVIDIA GPUs. \n",
    "- NIM microservices support models across domains like chat, embedding, reranking, and more from both the community and NVIDIA.\n",
    "\n",
    "#### NVIDIA API Catalog\n",
    "\n",
    "- [NVIDIA API Catalog](https://build.nvidia.com/explore/discover) is a hosted platform for accessing a wide range of microservices online.\n",
    "- You can test models on the catalog and then export them with an NVIDIA AI Enterprise license for on-premises or cloud deployment\n",
    "\n",
    "#### LlamaIndex Concepts\n",
    "\n",
    " - `Data connectors` ingest your existing data from their native source and format.\n",
    " - `Data indexes` structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
    " - `Engines` provide natural language access to your data for building context-augmented LLM apps.\n",
    "\n",
    "LlamaIndex also provides integrations like `llms-nvidia`, `embeddings-nvidia` & `nvidia-rerank` to work with NVIDIA microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca300278-5ff4-47c4-ab70-c6584ef73c9f",
   "metadata": {},
   "source": [
    "## Installation and Requirements\n",
    "\n",
    "Create a Python environment (preferably with Conda) using Python version 3.10.14. \n",
    "To install Jupyter Lab, refer to the [installation](https://jupyter.org/install) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a52a0-7e5e-4064-9665-cb947d600f84",
   "metadata": {},
   "source": [
    "## Getting Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36287c2e-8708-4006-8adf-851f06cce02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv_llamaindex2/lib/python3.10/site-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.2\n",
      "    Uninstalling pip-22.0.2:\n",
      "      Successfully uninstalled pip-22.0.2\n",
      "Successfully installed pip-24.2\n",
      "Collecting llama-index-core==0.10.50\n",
      "  Using cached llama_index_core-0.10.50-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.27.2)\n",
      "Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.50)\n",
      "  Using cached llama_cloud-0.0.6-py3-none-any.whl.metadata (750 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core==0.10.50) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (2.9.2)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.50) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.50) (0.14.0)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50) (2024.9.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.50) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.50) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.50) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.50) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.50) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.50) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.50) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.50) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.50) (24.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.50) (1.16.0)\n",
      "Using cached llama_index_core-0.10.50-py3-none-any.whl (15.4 MB)\n",
      "Using cached llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
      "Installing collected packages: llama-cloud, llama-index-core\n",
      "  Attempting uninstall: llama-cloud\n",
      "    Found existing installation: llama-cloud 0.1.0\n",
      "    Uninstalling llama-cloud-0.1.0:\n",
      "      Successfully uninstalled llama-cloud-0.1.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.14\n",
      "    Uninstalling llama-index-core-0.11.14:\n",
      "      Successfully uninstalled llama-index-core-0.11.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-cloud>=0.0.11, but you have llama-cloud 0.0.6 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-llms-openai 0.2.9 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-llms-openai-like 0.1.3 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.2.9 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-parse 0.5.6 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.50 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-cloud-0.0.6 llama-index-core-0.10.50\n",
      "Collecting llama-index-readers-file==0.1.25\n",
      "  Using cached llama_index_readers_file-0.1.25-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (4.12.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (0.10.50)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-readers-file==0.1.25) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.1.25) (2.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.27.2)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.9.2)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.14.0)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.9.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file==0.1.25) (1.16.0)\n",
      "Using cached llama_index_readers_file-0.1.25-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: llama-index-readers-file\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.2.2\n",
      "    Uninstalling llama-index-readers-file-0.2.2:\n",
      "      Successfully uninstalled llama-index-readers-file-0.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.50 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-readers-file<0.3.0,>=0.2.0, but you have llama-index-readers-file 0.1.25 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-readers-file-0.1.25\n",
      "Collecting llama-index-llms-nvidia==0.1.3\n",
      "  Using cached llama_index_llms_nvidia-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-nvidia==0.1.3) (0.10.50)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.17 (from llama-index-llms-nvidia==0.1.3)\n",
      "  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Requirement already satisfied: llama-index-llms-openai-like<0.2.0,>=0.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-nvidia==0.1.3) (0.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.27.2)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.47.0)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-core<0.11.0,>=0.10.0 (from llama-index-llms-nvidia==0.1.3)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.9.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (4.44.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.0.3)\n",
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.9.11)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.1.1)\n",
      "Requirement already satisfied: filelock in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (24.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv_llamaindex2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-nvidia==0.1.3) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.2.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.0->llama-index-llms-nvidia==0.1.3) (1.16.0)\n",
      "Using cached llama_index_llms_nvidia-0.1.3-py3-none-any.whl (4.3 kB)\n",
      "Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core, llama-index-llms-openai, llama-index-llms-nvidia\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.50\n",
      "    Uninstalling llama-index-core-0.10.50:\n",
      "      Successfully uninstalled llama-index-core-0.10.50\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.9\n",
      "    Uninstalling llama-index-llms-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.14 requires llama-index-core<0.12.0,>=0.11.14, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-llms-openai<0.3.0,>=0.2.9, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index 0.11.14 requires llama-index-readers-file<0.3.0,>=0.2.0, but you have llama-index-readers-file 0.1.25 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-llms-openai<0.3.0,>=0.2.9, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-cloud>=0.0.11, but you have llama-cloud 0.0.6 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.1 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.1.31 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-parse 0.5.6 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.10.68.post1 llama-index-llms-nvidia-0.1.3 llama-index-llms-openai-0.1.31\n",
      "Collecting llama-index-embeddings-nvidia==0.1.4\n",
      "  Using cached llama_index_embeddings_nvidia-0.1.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.9 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-embeddings-nvidia==0.1.4) (0.10.68.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.9->llama-index-embeddings-nvidia==0.1.4) (1.2.2)\n",
      "Using cached llama_index_embeddings_nvidia-0.1.4-py3-none-any.whl (5.5 kB)\n",
      "Installing collected packages: llama-index-embeddings-nvidia\n",
      "Successfully installed llama-index-embeddings-nvidia-0.1.4\n",
      "Collecting llama-index-postprocessor-nvidia-rerank==0.1.2\n",
      "  Using cached llama_index_postprocessor_nvidia_rerank-0.1.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.35 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-postprocessor-nvidia-rerank==0.1.2) (0.10.68.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv_llamaindex2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv_llamaindex2/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv_llamaindex2/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv_llamaindex2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv_llamaindex2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv_llamaindex2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv_llamaindex2/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index-postprocessor-nvidia-rerank==0.1.2) (1.2.2)\n",
      "Using cached llama_index_postprocessor_nvidia_rerank-0.1.2-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: llama-index-postprocessor-nvidia-rerank\n",
      "Successfully installed llama-index-postprocessor-nvidia-rerank-0.1.2\n",
      "Requirement already satisfied: ipywidgets==8.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipywidgets==8.1.3) (3.0.13)\n",
      "Requirement already satisfied: decorator in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.3) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv_llamaindex2/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.3) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv_llamaindex2/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.3) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv_llamaindex2/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.1.3) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv_llamaindex2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv_llamaindex2/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets==8.1.3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "!pip install --upgrade pip\n",
    "!pip install llama-index-core==0.10.50\n",
    "!pip install llama-index-readers-file==0.1.25\n",
    "!pip install llama-index-llms-nvidia==0.1.3\n",
    "!pip install llama-index-embeddings-nvidia==0.1.4\n",
    "!pip install llama-index-postprocessor-nvidia-rerank==0.1.2\n",
    "!pip install ipywidgets==8.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04495732-c2db-4c97-91d0-96708814334d",
   "metadata": {},
   "source": [
    "To get started you need a `NVIDIA_API_KEY` to use NVIDIA AI Foundation models:\n",
    "\n",
    "1) Create a free account with [NVIDIA](https://build.nvidia.com/explore/discover).\n",
    "2) Click on your model of choice.\n",
    "3) Under Input select the Python tab, and click **Get API Key** and then click **Generate Key**.\n",
    "4) Copy and save the generated key as NVIDIA_API_KEY. From there, you should have access to the endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb51115-79f8-48c3-b3ee-d434916945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvidia_api_key.startswith(\"nvapi-\"), f\"{nvidia_api_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25656ab5-0046-4e27-be65-b3d3d547b4c6",
   "metadata": {},
   "source": [
    "## RAG Example using LLM and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e86bc0-e9c5-4a2b-be0e-7fca0331e886",
   "metadata": {},
   "source": [
    "### 1) Initialize the LLM\n",
    "\n",
    "`llama-index-llms-nvidia`, also known as NVIDIA's LLM connector,\n",
    "allows your connect to and generate from compatible models available on the NVIDIA API catalog.\n",
    "\n",
    "Here we will use **mixtral-8x7b-instruct-v0.1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f7bdd3-2c6f-4ba2-bd89-175cedbf4f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/polabs2/Code/RPG_te\n",
      "[nltk_data]     acher/venv_llamaindex2/lib/python3.10/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# Settings enables global configuration as a singleton object throughout your application.\n",
    "# Here, it is used to set the LLM, embedding model, and text splitter configurations globally.\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "# Here we are using mixtral-8x7b-instruct-v0.1 model from API Catalog\n",
    "Settings.llm = NVIDIA(model=\"meta/llama-3.1-405b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc87a6-2f83-4652-95f1-cf349db8bad6",
   "metadata": {},
   "source": [
    "### 2) Intiatlize the embedding\n",
    "\n",
    "We selected **NV-Embed-QA** as the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88f7838-b9f9-4fc5-8779-84df6cb26017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
    "Settings.embed_model = NVIDIAEmbedding(model=\"NV-Embed-QA\", truncate=\"END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9862f2e-5055-4fe4-818d-708091243d74",
   "metadata": {},
   "source": [
    "### 3) Obtain some toy text dataset\n",
    "Here we are loading a toy data from a text documents and in real-time data can be loaded from various sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b16b3-43ac-4269-9f37-05a33efe24fb",
   "metadata": {},
   "source": [
    "Real world documents can be very long, this makes it hard to fit in the context window of many models. Even for those models that could fit the full post in their context window, models can struggle to find information in very long inputs.\n",
    "\n",
    "To handle this we’ll split the Document into chunks for embedding and vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804c85f6-181b-4291-a685-d6b378015544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example we load a toy data set (it's a simple text file with some information about Sweden)\n",
    "TOY_DATA_PATH = \"/home/polabs2/Code/RPG_teacher/data/out\"\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=400)\n",
    "documents = SimpleDirectoryReader(TOY_DATA_PATH).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a7da3-b6e7-46f1-9c31-3c6ef5f04d56",
   "metadata": {},
   "source": [
    "Note:\n",
    " - `SimpleDirectoryReader` takes care of storing basic file information such as the filename, filepath, and file type as metadata by default. This metadata can be used to keep track of the source file, allowing us to use it later for citation or metadata filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867df18-11c8-45ea-b81c-1603459431f9",
   "metadata": {},
   "source": [
    "### 4) Process the documents into VectorStoreIndex\n",
    "\n",
    "In RAG, your data is loaded and prepared for queries or \"indexed\". User queries act on the index, which filters your data down to the most relevant context. This context and your query then go to the LLM along with a prompt, and the LLM provides a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d7b2fbd-8cb1-4d68-9659-2426b9ecffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "# When you use from_documents, your Documents are split into chunks and parsed into Node objects\n",
    "# By default, VectorStoreIndex stores everything in memory\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe85dad-12bb-47d2-a407-9b89b5270d4e",
   "metadata": {},
   "source": [
    "### 5) Create a Query Engine to ask question over your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de3e07d-5fbe-4fe7-8f23-ed0b082f2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a Query engine for this index.\n",
    "query_engine = index.as_query_engine(similarity_top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d4aa38b-ae1a-4d31-857b-55400b6233b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The riddle Bilbo Baggins used to win the Ring from Gollum was not the one described in the passage, which was \"Nolegs lay on oneleg twolegs sat near on threelegs fourlegs got some\". This riddle was answered by Gollum, and then he asked a new riddle. The correct answer is still \"What have I got in my pocket?\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What was the riddle Bilbo Baggins used to win the Ring from Gollum?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa362c9-48ab-4646-bc29-bc2aca92505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilbo Baggins is a hobbit with a mix of courage and wisdom, who values simple pleasures like food, cheer, and song, and has a capacity for adventure that sets him apart from his comfort-loving family. Despite being a Baggins, he has inherited a sense of adventure and a bit of queerness from his Took side, which waited for a chance to emerge.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is Bilbo Baggins?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29478b0-0fb1-4678-93cd-b159dc9884a7",
   "metadata": {},
   "source": [
    "## RAG Example with LLM, Embedding & Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e763860-d4ca-491c-a11b-5bcf05a2ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three open-ended questions on web site design that are thematically set in the Hobbit:\n",
      "\n",
      "1. As Bilbo and the dwarves navigate the treacherous waters of the river, they come across a mysterious and ancient bridge. If you were tasked with designing a website for a company that specializes in bridge-building, how would you create a sense of stability and trust for visitors, while also showcasing the company's expertise and innovative approaches to bridge design?\n",
      "\n",
      "2. The elves of Rivendell are known for their exceptional craftsmanship and attention to detail. If you were designing a website for an elven artisan, how would you balance the need to showcase their intricate and beautiful work with the need to create a clean and simple user experience?\n",
      "\n",
      "3. The Lonely Mountain is a place of legend and myth, a symbol of the dwarves' rich history and culture. If you were designing a website for a museum or cultural institution dedicated to the history of the Lonely Mountain, how would you create an immersive and engaging experience for visitors, while also conveying the significance and importance of the mountain and its stories?\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Create three open-ended questions on web site design that are also thematically set in the Hobbit.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b88a91ed-5905-474e-8d8e-f5d887638a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all the chapters in the Hobbit:\n",
      "\n",
      "1. Chapter I: AN UNEXPECTED PARTY\n",
      "2. Chapter II: ROAST MUTTON\n",
      "3. Chapter III: A SHORT REST\n",
      "4. Chapter IV: OVER HILL AND UNDER HILL\n",
      "5. Chapter V: RIDDLES IN THE DARK\n",
      "6. Chapter VI: OUT OF THE FRYINGPAN INTO THE FIRE\n",
      "7. Chapter VII: QUEER LODGINGS\n",
      "8. Chapter VIII: FLIES AND SPIDERS\n",
      "9. Chapter IX: BARRELS OUT OF BOND\n",
      "10. Chapter X: A WARM WELCOME\n",
      "11. Chapter XI: ON THE DOORSTEP\n",
      "12. Chapter XII: INSIDE INFORMATION\n",
      "13. Chapter XIII: NOT AT HOME\n",
      "14. Chapter XIV: FIRE AND WATER\n",
      "15. Chapter XV: THE GATHERING OF THE CLOUDS\n",
      "16. Chapter XVI: A THIEF IN THE NIGHT\n",
      "17. Chapter XVII: THE CLOUDS BURST\n",
      "18. Chapter XVIII: THE RETURN JOURNEY\n",
      "19. Chapter XIX: THE LAST STAGE\n"
     ]
    }
   ],
   "source": [
    "# Let's test a more complex query using the above LLM Embedding query_engine and see if the reranker can help.\n",
    "response = query_engine.query(    \"What are all the chapters in the Hobbit?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b048f0-6258-43af-a799-6e58859cba99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'document'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/RPG_teacher/venv_llamaindex2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m doc_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/polabs2/Code/RPG_teacher/data/chapter_summary_notes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter the data for the document \"hobbit\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m doc_data \u001b[38;5;241m=\u001b[39m doc_data[\u001b[43mdoc_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhobbit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate over the rows in the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/RPG_teacher/venv_llamaindex2/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Code/RPG_teacher/venv_llamaindex2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "doc_data = pd.read_csv('/home/polabs2/Code/RPG_teacher/data/chapter_summary_notes.csv', delimiter='\\t', header=0)\n",
    "\n",
    "# Filter the data for the document \"hobbit\"\n",
    "doc_data = doc_data[doc_data['document'] == 'hobbit']\n",
    "print(doc_data.head(2))\n",
    "\n",
    "# Iterate over the rows in the DataFrame\n",
    "for i, row in doc_data.iterrows():\n",
    "    chapter = row['chapter']\n",
    "    text = row['text']\n",
    "    \n",
    "    # Generate the query string\n",
    "    q = f\"You are a helpful book summarizing assistant. Please use the provided context to summarize the following chapter into about 10 events: chapter {chapter} {text}\"\n",
    "    \n",
    "    # Send the query to the engine\n",
    "    response = query_engine.query(q)\n",
    "    \n",
    "    # Print the response\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3854c7-68a3-45b4-9e69-2c4e583d651f",
   "metadata": {},
   "source": [
    "### Enhancing accuracy for single data sources\n",
    "\n",
    "This example demonstrates how a re-ranking model can be used to combine retrieval results and improve accuracy during retrieval of documents.\n",
    "\n",
    "Typically, reranking is a critical piece of high-accuracy, efficient retrieval pipelines. Generally, there are two important use cases:\n",
    "\n",
    "- Combining results from multiple data sources\n",
    "- Enhancing accuracy for single data sources\n",
    "\n",
    "Here, we focus on demonstrating only the second use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8677e-a37f-42e2-8fea-4c4413f7d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will narrow the collection to 40 results and further narrow it to 4 with the reranker.\n",
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "\n",
    "reranker_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=40, node_postprocessors=[NVIDIARerank(top_n=4)]\n",
    ")\n",
    "\n",
    "response = reranker_query_engine.query(\n",
    "    \"What are the names of all the dwarves on Bilbo's adventure?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c289d-b10f-4bad-bb55-edc779e544f4",
   "metadata": {},
   "source": [
    "#### Note:\n",
    " - In this notebook, we used NVIDIA NIM microservices from the NVIDIA API Catalog.\n",
    " - The above APIs, NVIDIA (llms), NVIDIAEmbedding, and NVIDIARerank, also support self-hosted microservices.\n",
    " - Change the `base_url` to your deployed NIM URL\n",
    " - Example: NVIDIA(model=\"meta/llama3-8b-instruct\", base_url=\"http://your-nim-host-address:8000/v1\")\n",
    " - NIM can be hosted locally using Docker, following the [NVIDIA NIM for LLMs](https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea831a-76a5-431f-9b7f-f5bad5cb567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code snippet if you want to use a self-hosted NIM\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "llm = NVIDIA(model=\"meta/llama3-8b-instruct\", base_url=\"http://your-nim-host-address:8000/v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_llamaindex2)",
   "language": "python",
   "name": "venv_llamaindex2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
